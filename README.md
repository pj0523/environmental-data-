For project content and some techniqual tools, this project is for for crawling air pollution data (2013-2019) from the webï¼ˆhttps://www.aqistudy.cn/historydata/) using selenium and scrapy, including setting up defect logging in scrapy for checking unvisited url links.  P.S. I do not think the air pollution data in this website is highly reliable, because it does not clarify how to average the 24hours data for one day result. I  have some other reliable datasets about air pollution from other web. Welcome to contact me to get it without any commercial purpose. Hope we can do our own contribution to protect our environment. 
In terms of detailed techniqual issues about missing some urls due to the network environment, like internet speed. Hence, I set up log in the settings.py for the following steps to check which urls I fail to visit.
